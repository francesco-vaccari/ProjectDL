{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import clip\n",
    "import json\n",
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "modelCLIP, preprocess = clip.load(\"ViT-B/32\", device=device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T14:06:31.238137Z",
     "end_time": "2023-04-30T14:06:34.571434Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29559\n",
      "12667\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../refcocog/images/COCO_train2014_8365    438331\\nName: image_id, dtype: int64.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(val))\n\u001B[1;32m     10\u001B[0m train_image, train_bbox \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_dataloader))\n\u001B[0;32m---> 11\u001B[0m display(\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetImage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_image\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43midx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Projects/University/MachineLearning/DLProject/ProjectDL/RefcocogDataset.py:42\u001B[0m, in \u001B[0;36mRefcocogDataset.getImage\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetImage\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m     41\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mannotations\u001B[38;5;241m.\u001B[39miloc[idx]\n\u001B[0;32m---> 42\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getimage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m image\n",
      "File \u001B[0;32m~/Projects/University/MachineLearning/DLProject/ProjectDL/RefcocogDataset.py:53\u001B[0m, in \u001B[0;36mRefcocogDataset.__getimage\u001B[0;34m(self, id)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getimage\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mid\u001B[39m):\n\u001B[0;32m---> 53\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIMAGES_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCOCO_train2014_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzfill\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/University/MachineLearning/DLProject/venv/lib/python3.9/site-packages/PIL/Image.py:3236\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   3233\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[1;32m   3235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[0;32m-> 3236\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3237\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   3239\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../refcocog/images/COCO_train2014_8365    438331\\nName: image_id, dtype: int64.jpg'"
     ]
    }
   ],
   "source": [
    "from RefcocogDataset import RefcocogDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = RefcocogDataset(\"../refcocog\", split=\"train\", transform=preprocess)\n",
    "train, val = dataset.splitTrainVal([0.7, 0.3])\n",
    "train_dataloader = DataLoader(train)\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "\n",
    "train_image, train_bbox = next(iter(train_dataloader))\n",
    "display(dataset.getImage(train_image['idx'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T13:34:34.968620Z",
     "end_time": "2023-04-30T13:34:38.209584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       image_id  split                                          sentences   \n5023     519404  train  [{'tokens': ['two', 'woman', 'one', 'in', 'bla...  \\\n5024     181828  train  [{'tokens': ['a', 'tv', 'with', 'a', 'woman', ...   \n5025      38850  train  [{'tokens': ['a', 'young', 'boy', 'doing', 'a'...   \n5026     393325  train  [{'tokens': ['a', 'long', '-', 'horn', ',', 'l...   \n5027     289971  train  [{'tokens': ['the', 'woman', 'in', 'black', 'd...   \n...         ...    ...                                                ...   \n49817    426282  train  [{'tokens': ['blue', 'and', 'white', 'train'],...   \n49818    365259  train  [{'tokens': ['man', 'in', 'black', 'shirt', 'h...   \n49819      3518  train  [{'tokens': ['a', 'long', 'banana'], 'raw': 'a...   \n49820    302199  train  [{'tokens': ['a', 'guy', 'in', 'black', 'jacke...   \n49821    573297  train  [{'tokens': ['a', 'person', 'in', 'red', 'dres...   \n\n        ann_id  \n5023   1241542  \n5024     33583  \n5025    442348  \n5026     71545  \n5027    209158  \n...        ...  \n49817   366955  \n49818   481913  \n49819  1042682  \n49820   473946  \n49821   472971  \n\n[42226 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>split</th>\n      <th>sentences</th>\n      <th>ann_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5023</th>\n      <td>519404</td>\n      <td>train</td>\n      <td>[{'tokens': ['two', 'woman', 'one', 'in', 'bla...</td>\n      <td>1241542</td>\n    </tr>\n    <tr>\n      <th>5024</th>\n      <td>181828</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'tv', 'with', 'a', 'woman', ...</td>\n      <td>33583</td>\n    </tr>\n    <tr>\n      <th>5025</th>\n      <td>38850</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'young', 'boy', 'doing', 'a'...</td>\n      <td>442348</td>\n    </tr>\n    <tr>\n      <th>5026</th>\n      <td>393325</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'long', '-', 'horn', ',', 'l...</td>\n      <td>71545</td>\n    </tr>\n    <tr>\n      <th>5027</th>\n      <td>289971</td>\n      <td>train</td>\n      <td>[{'tokens': ['the', 'woman', 'in', 'black', 'd...</td>\n      <td>209158</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49817</th>\n      <td>426282</td>\n      <td>train</td>\n      <td>[{'tokens': ['blue', 'and', 'white', 'train'],...</td>\n      <td>366955</td>\n    </tr>\n    <tr>\n      <th>49818</th>\n      <td>365259</td>\n      <td>train</td>\n      <td>[{'tokens': ['man', 'in', 'black', 'shirt', 'h...</td>\n      <td>481913</td>\n    </tr>\n    <tr>\n      <th>49819</th>\n      <td>3518</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'long', 'banana'], 'raw': 'a...</td>\n      <td>1042682</td>\n    </tr>\n    <tr>\n      <th>49820</th>\n      <td>302199</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'guy', 'in', 'black', 'jacke...</td>\n      <td>473946</td>\n    </tr>\n    <tr>\n      <th>49821</th>\n      <td>573297</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'person', 'in', 'red', 'dres...</td>\n      <td>472971</td>\n    </tr>\n  </tbody>\n</table>\n<p>42226 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'images', 'licenses', 'annotations', 'categories'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                             segmentation         area   \n0       [[21.11, 239.09, 16.31, 274.6, 198.65, 349.45,...  48667.84090  \\\n1       [[474.17, 215.44, 342.4, 201.98, 317.39, 195.2...  10501.20610   \n2       [[326.4, 318.87, 320.05, 305.25, 323.68, 274.8...   3110.01535   \n3       [[283.47, 194.46, 271.43, 192.79, 274.44, 189....     39.81120   \n4       [[320.17, 195.66, 319.05, 221.23, 425.78, 234....   6405.16950   \n...                                                   ...          ...   \n208955  [[127.61, 166.47, 126.11, 161.71, 124.6, 156.9...    566.71230   \n208956  [[421.07, 194.84, 415.69, 194.84, 409.37, 199....    729.36245   \n208957  [[474.39, 262.44, 483.02, 246.9, 470.08, 80.36...  88909.53885   \n208958  [[127.28, 304.18, 392.63, 298.79, 501.57, 298....  59106.64675   \n208959  [[158.56, 212.49, 158.56, 94.92, 467.06, 85.21...  37887.19300   \n\n        iscrowd  image_id                              bbox  category_id   \n0             0    131074   [16.31, 141.21, 421.29, 208.24]           65  \\\n1             0    131074    [299.12, 136.58, 241.7, 88.85]           65   \n2             0    131074    [320.05, 248.05, 79.89, 83.07]           31   \n3             0    131074     [271.43, 189.61, 14.22, 4.85]           75   \n4             0    131074   [319.05, 195.66, 184.54, 98.94]           65   \n...         ...       ...                               ...          ...   \n208955        0    393207     [124.6, 139.15, 19.05, 41.61]            1   \n208956        0    393207    [408.42, 192.94, 39.21, 25.93]           31   \n208957        0    524286    [137.85, 0.97, 346.03, 280.45]           73   \n208958        0    524286  [127.28, 298.79, 376.45, 163.95]           76   \n208959        0    524286    [158.56, 85.21, 318.2, 127.28]           76   \n\n             id  \n0        318235  \n1        319598  \n2       1174042  \n3       1630619  \n4       1957252  \n...         ...  \n208955  1202801  \n208956  1836790  \n208957  1099077  \n208958  1116665  \n208959  1635174  \n\n[208960 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segmentation</th>\n      <th>area</th>\n      <th>iscrowd</th>\n      <th>image_id</th>\n      <th>bbox</th>\n      <th>category_id</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[21.11, 239.09, 16.31, 274.6, 198.65, 349.45,...</td>\n      <td>48667.84090</td>\n      <td>0</td>\n      <td>131074</td>\n      <td>[16.31, 141.21, 421.29, 208.24]</td>\n      <td>65</td>\n      <td>318235</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[474.17, 215.44, 342.4, 201.98, 317.39, 195.2...</td>\n      <td>10501.20610</td>\n      <td>0</td>\n      <td>131074</td>\n      <td>[299.12, 136.58, 241.7, 88.85]</td>\n      <td>65</td>\n      <td>319598</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[326.4, 318.87, 320.05, 305.25, 323.68, 274.8...</td>\n      <td>3110.01535</td>\n      <td>0</td>\n      <td>131074</td>\n      <td>[320.05, 248.05, 79.89, 83.07]</td>\n      <td>31</td>\n      <td>1174042</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[283.47, 194.46, 271.43, 192.79, 274.44, 189....</td>\n      <td>39.81120</td>\n      <td>0</td>\n      <td>131074</td>\n      <td>[271.43, 189.61, 14.22, 4.85]</td>\n      <td>75</td>\n      <td>1630619</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[320.17, 195.66, 319.05, 221.23, 425.78, 234....</td>\n      <td>6405.16950</td>\n      <td>0</td>\n      <td>131074</td>\n      <td>[319.05, 195.66, 184.54, 98.94]</td>\n      <td>65</td>\n      <td>1957252</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>208955</th>\n      <td>[[127.61, 166.47, 126.11, 161.71, 124.6, 156.9...</td>\n      <td>566.71230</td>\n      <td>0</td>\n      <td>393207</td>\n      <td>[124.6, 139.15, 19.05, 41.61]</td>\n      <td>1</td>\n      <td>1202801</td>\n    </tr>\n    <tr>\n      <th>208956</th>\n      <td>[[421.07, 194.84, 415.69, 194.84, 409.37, 199....</td>\n      <td>729.36245</td>\n      <td>0</td>\n      <td>393207</td>\n      <td>[408.42, 192.94, 39.21, 25.93]</td>\n      <td>31</td>\n      <td>1836790</td>\n    </tr>\n    <tr>\n      <th>208957</th>\n      <td>[[474.39, 262.44, 483.02, 246.9, 470.08, 80.36...</td>\n      <td>88909.53885</td>\n      <td>0</td>\n      <td>524286</td>\n      <td>[137.85, 0.97, 346.03, 280.45]</td>\n      <td>73</td>\n      <td>1099077</td>\n    </tr>\n    <tr>\n      <th>208958</th>\n      <td>[[127.28, 304.18, 392.63, 298.79, 501.57, 298....</td>\n      <td>59106.64675</td>\n      <td>0</td>\n      <td>524286</td>\n      <td>[127.28, 298.79, 376.45, 163.95]</td>\n      <td>76</td>\n      <td>1116665</td>\n    </tr>\n    <tr>\n      <th>208959</th>\n      <td>[[158.56, 212.49, 158.56, 94.92, 467.06, 85.21...</td>\n      <td>37887.19300</td>\n      <td>0</td>\n      <td>524286</td>\n      <td>[158.56, 85.21, 318.2, 127.28]</td>\n      <td>76</td>\n      <td>1635174</td>\n    </tr>\n  </tbody>\n</table>\n<p>208960 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[637.81, 166.7, 2.19, 4.99]\n"
     ]
    },
    {
     "data": {
      "text/plain": "       license                        file_name   \n0            1  COCO_train2014_000000131074.jpg  \\\n1            3  COCO_train2014_000000524291.jpg   \n2            7  COCO_train2014_000000524297.jpg   \n3            4  COCO_train2014_000000393228.jpg   \n4            5  COCO_train2014_000000131075.jpg   \n...        ...                              ...   \n25794        1  COCO_train2014_000000393193.jpg   \n25795        5  COCO_train2014_000000393195.jpg   \n25796        3  COCO_train2014_000000131058.jpg   \n25797        4  COCO_train2014_000000393207.jpg   \n25798        5  COCO_train2014_000000524286.jpg   \n\n                              coco_url  height  width        date_captured   \n0      http://mscoco.org/images/131074     428    640  2013-11-21 01:03:06  \\\n1      http://mscoco.org/images/524291     426    640  2013-11-18 09:59:07   \n2      http://mscoco.org/images/524297     446    640  2013-11-18 11:56:12   \n3      http://mscoco.org/images/393228     427    640  2013-11-18 03:13:38   \n4      http://mscoco.org/images/131075     640    478  2013-11-24 01:06:02   \n...                                ...     ...    ...                  ...   \n25794  http://mscoco.org/images/393193     380    500  2013-11-24 06:09:15   \n25795  http://mscoco.org/images/393195     482    640  2013-11-17 02:36:17   \n25796  http://mscoco.org/images/131058     480    640  2013-11-24 12:55:51   \n25797  http://mscoco.org/images/393207     359    640  2013-11-16 16:57:28   \n25798  http://mscoco.org/images/524286     480    640  2013-11-22 01:08:02   \n\n                                              flickr_url      id  \n0      http://farm9.staticflickr.com/8308/7908210548_...  131074  \n1      http://farm2.staticflickr.com/1045/934293170_d...  524291  \n2      http://farm4.staticflickr.com/3007/2552566879_...  524297  \n3      http://farm8.staticflickr.com/7055/6987538203_...  393228  \n4      http://farm8.staticflickr.com/7252/7104000401_...  131075  \n...                                                  ...     ...  \n25794  http://farm1.staticflickr.com/27/54399546_14c7...  393193  \n25795  http://farm5.staticflickr.com/4028/4279727809_...  393195  \n25796  http://farm3.staticflickr.com/2755/4125176703_...  131058  \n25797  http://farm6.staticflickr.com/5133/5466742274_...  393207  \n25798  http://farm4.staticflickr.com/3286/3160643026_...  524286  \n\n[25799 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>license</th>\n      <th>file_name</th>\n      <th>coco_url</th>\n      <th>height</th>\n      <th>width</th>\n      <th>date_captured</th>\n      <th>flickr_url</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>COCO_train2014_000000131074.jpg</td>\n      <td>http://mscoco.org/images/131074</td>\n      <td>428</td>\n      <td>640</td>\n      <td>2013-11-21 01:03:06</td>\n      <td>http://farm9.staticflickr.com/8308/7908210548_...</td>\n      <td>131074</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>COCO_train2014_000000524291.jpg</td>\n      <td>http://mscoco.org/images/524291</td>\n      <td>426</td>\n      <td>640</td>\n      <td>2013-11-18 09:59:07</td>\n      <td>http://farm2.staticflickr.com/1045/934293170_d...</td>\n      <td>524291</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>COCO_train2014_000000524297.jpg</td>\n      <td>http://mscoco.org/images/524297</td>\n      <td>446</td>\n      <td>640</td>\n      <td>2013-11-18 11:56:12</td>\n      <td>http://farm4.staticflickr.com/3007/2552566879_...</td>\n      <td>524297</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>COCO_train2014_000000393228.jpg</td>\n      <td>http://mscoco.org/images/393228</td>\n      <td>427</td>\n      <td>640</td>\n      <td>2013-11-18 03:13:38</td>\n      <td>http://farm8.staticflickr.com/7055/6987538203_...</td>\n      <td>393228</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>COCO_train2014_000000131075.jpg</td>\n      <td>http://mscoco.org/images/131075</td>\n      <td>640</td>\n      <td>478</td>\n      <td>2013-11-24 01:06:02</td>\n      <td>http://farm8.staticflickr.com/7252/7104000401_...</td>\n      <td>131075</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25794</th>\n      <td>1</td>\n      <td>COCO_train2014_000000393193.jpg</td>\n      <td>http://mscoco.org/images/393193</td>\n      <td>380</td>\n      <td>500</td>\n      <td>2013-11-24 06:09:15</td>\n      <td>http://farm1.staticflickr.com/27/54399546_14c7...</td>\n      <td>393193</td>\n    </tr>\n    <tr>\n      <th>25795</th>\n      <td>5</td>\n      <td>COCO_train2014_000000393195.jpg</td>\n      <td>http://mscoco.org/images/393195</td>\n      <td>482</td>\n      <td>640</td>\n      <td>2013-11-17 02:36:17</td>\n      <td>http://farm5.staticflickr.com/4028/4279727809_...</td>\n      <td>393195</td>\n    </tr>\n    <tr>\n      <th>25796</th>\n      <td>3</td>\n      <td>COCO_train2014_000000131058.jpg</td>\n      <td>http://mscoco.org/images/131058</td>\n      <td>480</td>\n      <td>640</td>\n      <td>2013-11-24 12:55:51</td>\n      <td>http://farm3.staticflickr.com/2755/4125176703_...</td>\n      <td>131058</td>\n    </tr>\n    <tr>\n      <th>25797</th>\n      <td>4</td>\n      <td>COCO_train2014_000000393207.jpg</td>\n      <td>http://mscoco.org/images/393207</td>\n      <td>359</td>\n      <td>640</td>\n      <td>2013-11-16 16:57:28</td>\n      <td>http://farm6.staticflickr.com/5133/5466742274_...</td>\n      <td>393207</td>\n    </tr>\n    <tr>\n      <th>25798</th>\n      <td>5</td>\n      <td>COCO_train2014_000000524286.jpg</td>\n      <td>http://mscoco.org/images/524286</td>\n      <td>480</td>\n      <td>640</td>\n      <td>2013-11-22 01:08:02</td>\n      <td>http://farm4.staticflickr.com/3286/3160643026_...</td>\n      <td>524286</td>\n    </tr>\n  </tbody>\n</table>\n<p>25799 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_PATH = \"../refcocog/\"\n",
    "BASE_IMG = BASE_PATH + \"images/\"\n",
    "annotations = pandas.read_pickle(BASE_PATH + \"annotations/refs(umd).p\")\n",
    "\n",
    "ann_dt = pandas.DataFrame.from_records(annotations).filter(items=[\"image_id\", \"split\", \"sentences\", \"ann_id\"])\n",
    "display(ann_dt[ann_dt.split == 'train'])\n",
    "\n",
    "instances = json.load(open(BASE_PATH + \"annotations/instances.json\", 'r'))\n",
    "print(instances.keys())\n",
    "instances_dt = pandas.DataFrame.from_records(instances['annotations'])\n",
    "display(instances_dt)\n",
    "\n",
    "print(instances_dt['bbox'].max())\n",
    "\n",
    "images_dt = pandas.DataFrame.from_records(instances['images'])\n",
    "display(images_dt)\n",
    "\n",
    "\n",
    "train_ann = [ann for ann in annotations if ann['split'] == 'train']\n",
    "test_ann = [ann for ann in annotations if ann['split'] == 'test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T14:07:21.626058Z",
     "end_time": "2023-04-30T14:07:25.203457Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge two pandas dataframe to obtain a single dataframe with all the information we need to run all the computations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       image_id  split                                          sentences   \n40652         9  train  [{'tokens': ['a', 'yellow', 'rectangle', 'bowl...  \\\n16534         9  train  [{'tokens': ['a', 'pink', 'plastic', 'box', 'w...   \n19208         9  train  [{'tokens': ['container', 'holding', 'fruit'],...   \n8910         49  train  [{'tokens': ['a', 'black', 'horse', 'white', '...   \n28365        49  train  [{'tokens': ['a', 'white', 'horse', 'with', 'a...   \n...         ...    ...                                                ...   \n7070     581839  train  [{'tokens': ['a', 'woman', 'standing', 'behind...   \n24806    581839  train  [{'tokens': ['the', 'woman', 'sitting', 'down'...   \n35588    581857  train  [{'tokens': ['a', 'woman', 'in', 'glasses', 's...   \n27081    581857  train  [{'tokens': ['the', 'back', 'of', 'an', 'older...   \n46606    581857  train  [{'tokens': ['the', 'woman', 'in', 'the', 'gre...   \n\n        ann_id  \n40652  1038967  \n16534  1534147  \n19208  1039564  \n8910     56407  \n28365    58884  \n...        ...  \n7070    495152  \n24806   485695  \n35588   470153  \n27081  1719310  \n46606   463958  \n\n[39848 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>split</th>\n      <th>sentences</th>\n      <th>ann_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>40652</th>\n      <td>9</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'yellow', 'rectangle', 'bowl...</td>\n      <td>1038967</td>\n    </tr>\n    <tr>\n      <th>16534</th>\n      <td>9</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'pink', 'plastic', 'box', 'w...</td>\n      <td>1534147</td>\n    </tr>\n    <tr>\n      <th>19208</th>\n      <td>9</td>\n      <td>train</td>\n      <td>[{'tokens': ['container', 'holding', 'fruit'],...</td>\n      <td>1039564</td>\n    </tr>\n    <tr>\n      <th>8910</th>\n      <td>49</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'black', 'horse', 'white', '...</td>\n      <td>56407</td>\n    </tr>\n    <tr>\n      <th>28365</th>\n      <td>49</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'white', 'horse', 'with', 'a...</td>\n      <td>58884</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7070</th>\n      <td>581839</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'woman', 'standing', 'behind...</td>\n      <td>495152</td>\n    </tr>\n    <tr>\n      <th>24806</th>\n      <td>581839</td>\n      <td>train</td>\n      <td>[{'tokens': ['the', 'woman', 'sitting', 'down'...</td>\n      <td>485695</td>\n    </tr>\n    <tr>\n      <th>35588</th>\n      <td>581857</td>\n      <td>train</td>\n      <td>[{'tokens': ['a', 'woman', 'in', 'glasses', 's...</td>\n      <td>470153</td>\n    </tr>\n    <tr>\n      <th>27081</th>\n      <td>581857</td>\n      <td>train</td>\n      <td>[{'tokens': ['the', 'back', 'of', 'an', 'older...</td>\n      <td>1719310</td>\n    </tr>\n    <tr>\n      <th>46606</th>\n      <td>581857</td>\n      <td>train</td>\n      <td>[{'tokens': ['the', 'woman', 'in', 'the', 'gre...</td>\n      <td>463958</td>\n    </tr>\n  </tbody>\n</table>\n<p>39848 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ann_dt['image_id']\n",
    "ann_dt[ids.isin(ids[ids.duplicated()])].sort_values('image_id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T15:55:49.125250Z",
     "end_time": "2023-04-30T15:55:49.158881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a_dt = ann_dt.merge(instances_dt[[\"id\", \"bbox\", \"area\"]], left_on=\"ann_id\", right_on=\"id\").drop(columns=\"id\")\n",
    "display(a_dt.head(1))\n",
    "\n",
    "train_split = a_dt[a_dt.split == \"train\"].reset_index()\n",
    "display(train_split)\n",
    "display(train_split.loc[[3]])\n",
    "test_split = a_dt[a_dt.split == \"test\"]\n",
    "display(test_split)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T11:29:04.234390Z",
     "end_time": "2023-04-30T11:29:04.390225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['test a long - horn , long - haired brown cow looking at the camera',\n 'test a brown bull in front of feeding tub']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item = train_split.iloc[3]\n",
    "display([f\"test {s['sent']}\" for s in item.sentences])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T12:04:37.550410Z",
     "end_time": "2023-04-30T12:04:37.554714Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run YOLO prediction on image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load YOLO model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:31:20.387718Z",
     "end_time": "2023-04-29T10:31:24.006796Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def YoloBBoxes(img):\n",
    "    result = model(img)\n",
    "    result.show()\n",
    "    bbox = result.pandas().xyxy[0]\n",
    "    bbox = bbox.reset_index()\n",
    "    bbox[\"tconfidence\"] = np.nan\n",
    "    bbox[\"crop\"] = np.nan\n",
    "    return bbox\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:31:24.009093Z",
     "end_time": "2023-04-29T10:31:24.010645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def CropImage(image, boxs):\n",
    "    crops = []\n",
    "\n",
    "    for index, row in boxs.iterrows():\n",
    "        box = (\n",
    "            row['xmin'],\n",
    "            row['ymin'],\n",
    "            row['xmax'],\n",
    "            row['ymax'],\n",
    "        )\n",
    "\n",
    "        crop = image.crop(box)\n",
    "\n",
    "        crops.append(crop)\n",
    "        boxs.at[index, 'crop'] = crop\n",
    "\n",
    "    return crops\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:31:24.012289Z",
     "end_time": "2023-04-29T10:31:24.013137Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute text similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:31:24.014396Z",
     "end_time": "2023-04-29T10:31:26.109772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ExtractSent(annotation):\n",
    "    return [f\"a photo of a {s['sent']}\" for s in annotation['sentences']]\n",
    "\n",
    "def ClipSimilarity(image, text):\n",
    "    image_features = modelCLIP.encode_image(image).float()\n",
    "    text_features = modelCLIP.encode_text(text).float()\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = image_features @ text_features.T\n",
    "    return similarity\n",
    "\n",
    "def ComputeTextSimilarity(c, boxes):\n",
    "    for index, row in boxes.iterrows():\n",
    "        # display(c[index])\n",
    "        text_simils = []\n",
    "\n",
    "        for sent in test_sent:\n",
    "            image = preprocess(row['crop']).unsqueeze(0).to(device)\n",
    "            text = clip.tokenize(sent).to(device)\n",
    "\n",
    "            text_simils.append(ClipSimilarity(image, text).detach().numpy())\n",
    "\n",
    "        boxes.at[index, \"tconfidence\"] = (np.array(text_simils).max())\n",
    "\n",
    "def ExtractBestMatch(boxes):\n",
    "    return boxes[boxes.tconfidence == boxes.tconfidence.max()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T10:31:26.112442Z",
     "end_time": "2023-04-29T10:31:26.113686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def CalculateIntersectionArea(fx1, fy1, fx2, fy2, sx1, sy1, sx2, sy2):\n",
    "    print(fx1, fy1, fx2, fy2, sx1, sy1, sx2, sy2)\n",
    "    dx = min(fx2, sx2) - max(fx1, sx1)\n",
    "    dy = min(fy2, sy2) - max(fy1, sy1)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        area = dx*dy\n",
    "    else:\n",
    "        area = 0\n",
    "    return area\n",
    "\n",
    "def VisualizeIntersections(image, best, ann):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(\n",
    "        [best_match.xmin, best_match.ymin, best_match.xmax, best_match.ymax],\n",
    "        outline=\"red\",\n",
    "        width=3\n",
    "    )\n",
    "    draw.rectangle(\n",
    "        [bbox_annotation[0], bbox_annotation[1], bbox_annotation[0] + bbox_annotation[2], bbox_annotation[1] + bbox_annotation[3]],\n",
    "        outline=\"blue\",\n",
    "        width=3\n",
    "    )\n",
    "    display(image)\n",
    "\n",
    "def CalculateIntersection(box, annotation):\n",
    "    return\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T11:37:45.862311Z",
     "end_time": "2023-04-29T11:37:45.863674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = a_dt.head(1)\n",
    "\n",
    "test_img = Image.open(BASE_IMG + \"COCO_train2014_\" + str(img['image_id'].values[0]).zfill(12) + \".jpg\")\n",
    "\n",
    "bbox = YoloBBoxes(test_img)\n",
    "crops = CropImage(test_img, bbox)\n",
    "\n",
    "test_sent = ExtractSent(test_ann[0])\n",
    "ComputeTextSimilarity(crops, bbox)\n",
    "display(bbox)\n",
    "\n",
    "best_match = ExtractBestMatch(bbox)\n",
    "\n",
    "bbox_annotation = img['bbox'].values[0]\n",
    "display(bbox_annotation)\n",
    "\n",
    "print(\"Best BBox Match\")\n",
    "display(best_match)\n",
    "display(best_match['crop'][1])\n",
    "\n",
    "VisualizeIntersections(test_img, best_match, bbox_annotation)\n",
    "\n",
    "area = CalculateIntersectionArea(\n",
    "    best_match.xmin.values[0], best_match.ymax.values[0], best_match.xmax.values[0], best_match.ymin.values[0],\n",
    "    bbox_annotation[0], bbox_annotation[1], bbox_annotation[0] + bbox_annotation[2], bbox_annotation[1] + bbox_annotation[3]\n",
    ")\n",
    "\n",
    "print(area)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T11:38:33.912370Z",
     "end_time": "2023-04-29T11:38:35.742520Z"
    }
   }
  }
 ]
}
